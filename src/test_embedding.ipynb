{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "from typing import Tuple\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from numpy import floating\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "DATA_FOLDER = Path(\"../data\")\n",
    "INPUT_FOLDER = DATA_FOLDER / \"query_eval\"\n",
    "RESULT_FOLDER = DATA_FOLDER / \"embedding_eval\"\n",
    "RESULT_V2_FOLDER = (\n",
    "    DATA_FOLDER / \"embedding_eval_v2\"\n",
    ")  # this contains the API call with type (QUERY or DOCUMENT)\n",
    "REGION = \"europe-west3\"\n",
    "PROJECT_ID = \"adesso-gcc-rtl-uc4\"\n",
    "EMBEDDING_MODELS = [\n",
    "    (\"gecko@001\", \"textembedding-gecko@001\"),\n",
    "    (\"gecko@002\", \"textembedding-gecko@002\"),\n",
    "    (\"gecko@003\", \"textembedding-gecko@003\"),\n",
    "    (\"gecko@00multilingual\", \"textembedding-gecko-multilingual@001\"),\n",
    "]\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file: Path, col_name: str) -> list[str]:\n",
    "    with open(file, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [\n",
    "            row[col_name].replace(\"ChromaDB:\\n\", \"\") for row in reader if row[col_name]\n",
    "        ]\n",
    "\n",
    "\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "def encode_texts_to_embeddings(\n",
    "    docs: list[str | TextEmbeddingInput],\n",
    "    embedding_model: TextEmbeddingModel,\n",
    "    instances_per_batch: int = 5,\n",
    "    requests_per_minute: int = 100,\n",
    ") -> list[Optional[list[float]]]:\n",
    "    # sentences = [TextEmbeddingInput(text=sentence) for sentence in sentences]\n",
    "    try:\n",
    "        embeddings = []\n",
    "        limiter = rate_limit(requests_per_minute)\n",
    "        while docs:\n",
    "            # Working in batches because the API accepts maximum 5\n",
    "            # documents per request to get embeddings\n",
    "            head, docs = (\n",
    "                docs[:instances_per_batch],\n",
    "                docs[instances_per_batch:],\n",
    "            )\n",
    "            chunk = embedding_model.get_embeddings(head)\n",
    "            embeddings.extend(chunk)\n",
    "            next(limiter)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception as e:\n",
    "        print(f\"Error while getting embeddings: {e}\")\n",
    "        return [None for _ in range(len(docs))]\n",
    "\n",
    "\n",
    "def get_distance(document: list[float], query_embedding: list[float]) -> floating[Any]:\n",
    "    return np.linalg.norm(np.array(document) - np.array(query_embedding))\n",
    "\n",
    "\n",
    "def get_text_embedding_df(\n",
    "    docs: list[str], query: str, embedding_models: list[Tuple[str, str]]\n",
    ") -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    df[\"result\"] = docs\n",
    "\n",
    "    for embedding_model_name, embedding_model in embedding_models:\n",
    "        model = TextEmbeddingModel.from_pretrained(embedding_model)\n",
    "\n",
    "        # get query embedding\n",
    "        query_embedding = model.get_embeddings([query])[0].values\n",
    "\n",
    "        # get text embeddings\n",
    "        df[embedding_model_name] = encode_texts_to_embeddings(docs, model)  # type: ignore\n",
    "\n",
    "        # get distance for each document embedding to the query embedding\n",
    "        distance_col = f\"{embedding_model_name}_distance\"\n",
    "        df[distance_col] = df[embedding_model_name].map(\n",
    "            lambda x: round(get_distance(x, query_embedding), 2)\n",
    "        )\n",
    "\n",
    "        # get order of the distance\n",
    "        df[f\"{embedding_model_name}_order\"] = df[distance_col].rank().astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAME = \"Semantic\"\n",
    "\n",
    "for csv_file in INPUT_FOLDER.glob(\"*.csv\"):\n",
    "    # query is in file name\n",
    "    query = \" \".join(csv_file.stem.split(\"_\"))\n",
    "    print(f\"Processing {csv_file} with query: {query}\")\n",
    "\n",
    "    # load texts\n",
    "    docs = load_csv(csv_file, COL_NAME)\n",
    "\n",
    "    # get df with embeddings and distances to query\n",
    "    df = get_text_embedding_df(docs, query, EMBEDDING_MODELS)\n",
    "    df.to_parquet(RESULT_FOLDER / f\"{csv_file.stem}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the CSV by removing embedding columns and re-ordering results\n",
    "for result_file in RESULT_FOLDER.glob(\"*.parquet\"):\n",
    "    df = pd.read_parquet(result_file)\n",
    "\n",
    "    # drop all columns that don't contain \"distance\" or \"order\"\n",
    "    df = df.loc[:, df.columns.str.contains(\"distance|order|result\")]\n",
    "\n",
    "    # copy index (+ 1) to new column \"rank\"\n",
    "    original_rank_col = \"original_rank\"\n",
    "    df[original_rank_col] = df.index + 1\n",
    "\n",
    "    # sort texts by each distance order (distance) column\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"_order\"):\n",
    "            result_col = col.replace(\"_order\", \"\")\n",
    "            helper_df = df[[\"result\", original_rank_col, col]].sort_values(by=col)\n",
    "            df[result_col + \"_result\"] = helper_df[\"result\"].values\n",
    "            df[col] = helper_df[col].values\n",
    "\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df.to_csv(RESULT_FOLDER / (result_file.stem + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
